{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_pruning_students Rohan",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanrb302/Complete-Python-3-Bootcamp/blob/master/CNN_pruning_students_Rohan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "outputId": "91b3af0c-1bc6-41be-a820-f5cb49814d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU"
      },
      "source": [
        "# untar\n",
        "# !tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTzcSoYl4T97",
        "outputId": "f5b16063-8b55-4b4e-abc8-24ee86bd54c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 25, 25, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 23, 23, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt",
        "outputId": "46d7836e-0a81-410c-e18a-c8d30c8fed3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.5626 - accuracy: 0.3037 - val_loss: 1.4974 - val_accuracy: 0.3798\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4808 - accuracy: 0.4021 - val_loss: 1.4530 - val_accuracy: 0.4253\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4560 - accuracy: 0.4310 - val_loss: 1.4337 - val_accuracy: 0.4535\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4384 - accuracy: 0.4505 - val_loss: 1.4231 - val_accuracy: 0.4657\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4234 - accuracy: 0.4685 - val_loss: 1.4021 - val_accuracy: 0.4883\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4128 - accuracy: 0.4806 - val_loss: 1.3954 - val_accuracy: 0.5006\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.4027 - accuracy: 0.4900 - val_loss: 1.3899 - val_accuracy: 0.4958\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3959 - accuracy: 0.4967 - val_loss: 1.3834 - val_accuracy: 0.5042\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3874 - accuracy: 0.5071 - val_loss: 1.3761 - val_accuracy: 0.5184\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3792 - accuracy: 0.5163 - val_loss: 1.3734 - val_accuracy: 0.5137\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3725 - accuracy: 0.5256 - val_loss: 1.3663 - val_accuracy: 0.5303\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3646 - accuracy: 0.5332 - val_loss: 1.3572 - val_accuracy: 0.5335\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3603 - accuracy: 0.5352 - val_loss: 1.3470 - val_accuracy: 0.5434\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3500 - accuracy: 0.5491 - val_loss: 1.3515 - val_accuracy: 0.5453\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3465 - accuracy: 0.5512 - val_loss: 1.3508 - val_accuracy: 0.5402\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3408 - accuracy: 0.5587 - val_loss: 1.3414 - val_accuracy: 0.5537\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3335 - accuracy: 0.5663 - val_loss: 1.3313 - val_accuracy: 0.5648\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3297 - accuracy: 0.5691 - val_loss: 1.3383 - val_accuracy: 0.5477\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3211 - accuracy: 0.5780 - val_loss: 1.3274 - val_accuracy: 0.5628\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3167 - accuracy: 0.5853 - val_loss: 1.3237 - val_accuracy: 0.5691\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3108 - accuracy: 0.5903 - val_loss: 1.3108 - val_accuracy: 0.5877\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3069 - accuracy: 0.5933 - val_loss: 1.3221 - val_accuracy: 0.5782\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3050 - accuracy: 0.5960 - val_loss: 1.3198 - val_accuracy: 0.5798\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3000 - accuracy: 0.6014 - val_loss: 1.3019 - val_accuracy: 0.6016\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2935 - accuracy: 0.6081 - val_loss: 1.2993 - val_accuracy: 0.6051\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2912 - accuracy: 0.6103 - val_loss: 1.2941 - val_accuracy: 0.6067\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2860 - accuracy: 0.6164 - val_loss: 1.2934 - val_accuracy: 0.6048\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2825 - accuracy: 0.6197 - val_loss: 1.2858 - val_accuracy: 0.6190\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2773 - accuracy: 0.6247 - val_loss: 1.2906 - val_accuracy: 0.6091\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2772 - accuracy: 0.6265 - val_loss: 1.2882 - val_accuracy: 0.6091\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2718 - accuracy: 0.6304 - val_loss: 1.2979 - val_accuracy: 0.6004\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2673 - accuracy: 0.6355 - val_loss: 1.2864 - val_accuracy: 0.6147\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2632 - accuracy: 0.6402 - val_loss: 1.3065 - val_accuracy: 0.5905\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2627 - accuracy: 0.6410 - val_loss: 1.2788 - val_accuracy: 0.6206\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2566 - accuracy: 0.6470 - val_loss: 1.2676 - val_accuracy: 0.6360\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2586 - accuracy: 0.6438 - val_loss: 1.2704 - val_accuracy: 0.6333\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2529 - accuracy: 0.6504 - val_loss: 1.2680 - val_accuracy: 0.6329\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2487 - accuracy: 0.6558 - val_loss: 1.2628 - val_accuracy: 0.6396\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2455 - accuracy: 0.6582 - val_loss: 1.2711 - val_accuracy: 0.6289\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2479 - accuracy: 0.6544 - val_loss: 1.2668 - val_accuracy: 0.6329\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2414 - accuracy: 0.6638 - val_loss: 1.2592 - val_accuracy: 0.6412\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2389 - accuracy: 0.6643 - val_loss: 1.2574 - val_accuracy: 0.6408\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2343 - accuracy: 0.6704 - val_loss: 1.2638 - val_accuracy: 0.6356\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2332 - accuracy: 0.6709 - val_loss: 1.2576 - val_accuracy: 0.6412\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2292 - accuracy: 0.6759 - val_loss: 1.2482 - val_accuracy: 0.6543\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2248 - accuracy: 0.6804 - val_loss: 1.2552 - val_accuracy: 0.6459\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2246 - accuracy: 0.6792 - val_loss: 1.2491 - val_accuracy: 0.6543\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2253 - accuracy: 0.6790 - val_loss: 1.2536 - val_accuracy: 0.6467\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2193 - accuracy: 0.6857 - val_loss: 1.2411 - val_accuracy: 0.6622\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2163 - accuracy: 0.6890 - val_loss: 1.2490 - val_accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "outputId": "84d2053a-92d4-4b1b-9ca5-b41cff88a157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2490 - accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjw94aij4T-C"
      },
      "source": [
        "# perform pruning here\n",
        "\n",
        "# get the weights \n",
        "weights = model.get_weights()\n",
        "\n",
        "# you can use set_weights() to set some weights to zero, e.g.,\n",
        "# some references for pruning techniques: https://arxiv.org/pdf/1810.05270v2.pdf, https://arxiv.org/pdf/2001.04062.pdf\n",
        "weights[8][:100]=0\n",
        "weights[7][:10]=0\n",
        "model.set_weights(weights)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxR1YlxJbLau"
      },
      "source": [
        "def weight_prune_dense_layer(k_weights, b_weights, k_sparsity):\n",
        "    \"\"\"\n",
        "    Takes in matrices of kernel and bias weights (for a dense\n",
        "      layer) and returns the unit-pruned versions of each\n",
        "    Args:\n",
        "      k_weights: 2D matrix of the \n",
        "      b_weights: 1D matrix of the biases of a dense layer\n",
        "      k_sparsity: percentage of weights to set to 0\n",
        "    Returns:\n",
        "      kernel_weights: sparse matrix with same shape as the original\n",
        "        kernel weight matrix\n",
        "      bias_weights: sparse array with same shape as the original\n",
        "        bias array\n",
        "    \"\"\"\n",
        "    # Copy the kernel weights and get ranked indeces of the abs\n",
        "    kernel_weights = np.copy(k_weights)\n",
        "    ind = np.unravel_index(\n",
        "        np.argsort(\n",
        "            np.abs(kernel_weights),\n",
        "            axis=None),\n",
        "        kernel_weights.shape)\n",
        "        \n",
        "    # Number of indexes to set to 0\n",
        "    cutoff = int(len(ind[0])*k_sparsity)\n",
        "    # The indexes in the 2D kernel weight matrix to set to 0\n",
        "    sparse_cutoff_inds = (ind[0][0:cutoff], ind[1][0:cutoff])\n",
        "    kernel_weights[sparse_cutoff_inds] = 0.\n",
        "        \n",
        "    # Copy the bias weights and get ranked indeces of the abs\n",
        "    bias_weights = np.copy(b_weights)\n",
        "    ind = np.unravel_index(\n",
        "        np.argsort(\n",
        "            np.abs(bias_weights), \n",
        "            axis=None), \n",
        "        bias_weights.shape)\n",
        "        \n",
        "    # Number of indexes to set to 0\n",
        "    cutoff = int(len(ind[0])*k_sparsity)\n",
        "    # The indexes in the 1D bias weight matrix to set to 0\n",
        "    sparse_cutoff_inds = (ind[0][0:cutoff])\n",
        "    bias_weights[sparse_cutoff_inds] = 0.\n",
        "    \n",
        "    return kernel_weights, bias_weights"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2Zs-tnbLTT"
      },
      "source": [
        "def sparsify_model(model, x_train, y_train,x_val,y_val, k_sparsity, pruning='weight'):\n",
        "    \"\"\"\n",
        "    Takes in a model made of dense layers and prunes the weights\n",
        "    Args:\n",
        "      model: Keras model\n",
        "      k_sparsity: target sparsity of the model\n",
        "    Returns:\n",
        "      sparse_model: sparsified copy of the previous model\n",
        "    \"\"\"\n",
        "    # Copying a temporary sparse model from our original\n",
        "    sparse_model = tf.keras.models.clone_model(model)\n",
        "    sparse_model.set_weights(model.get_weights())\n",
        "    \n",
        "    # Getting a list of the names of each component (w + b) of each layer\n",
        "    names = [weight.name for layer in sparse_model.layers for weight in layer.weights]\n",
        "    # Getting the list of the weights for each component (w + b) of each layer\n",
        "    weights = sparse_model.get_weights()\n",
        "    \n",
        "    # Initializing list that will contain the new sparse weights\n",
        "    newWeightList = []\n",
        "\n",
        "    # Iterate over all but the final 2 layers (the softmax)\n",
        "    for i in range(0, len(weights)-2, 2):\n",
        "        \n",
        "        if pruning=='weight':\n",
        "            kernel_weights, bias_weights = weight_prune_dense_layer(weights[i],\n",
        "                                                                    weights[i+1],\n",
        "                                                                    k_sparsity)\n",
        "        else:\n",
        "            print('does not match available pruning methods ( weight | unit )')\n",
        "        \n",
        "        # Append the new weight list with our sparsified kernel weights\n",
        "        newWeightList.append(kernel_weights)\n",
        "        \n",
        "        # Append the new weight list with our sparsified bias weights\n",
        "        newWeightList.append(bias_weights)\n",
        "\n",
        "    # Adding the unchanged weights of the final 2 layers\n",
        "    for i in range(len(weights)-2, len(weights)):\n",
        "        unmodified_weight = np.copy(weights[i])\n",
        "        newWeightList.append(unmodified_weight)\n",
        "\n",
        "    # Setting the weights of our model to the new ones\n",
        "    sparse_model.set_weights(newWeightList)\n",
        "    \n",
        "    # Re-compiling the Keras model (necessary for using `evaluate()`)\n",
        "    sparse_model.compile(\n",
        "        loss=tf.keras.losses.categorical_crossentropy,\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    # Printing the the associated loss & Accuracy for the k% sparsity\n",
        "    history = sparse_model.fit(train_images, train_labels, batch_size=32, epochs=50) \n",
        "    results = sparse_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "    print(results)\n",
        "    return sparse_model,history\n",
        " "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRcNXGXwYe6"
      },
      "source": [
        "old_weights= "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUuNXFjV4T-E",
        "outputId": "664f04d1-1dfb-4b3c-ca18-f75f01b7a551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 1.2506 - accuracy: 0.6519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "outputId": "d894970c-d381-4be7-dbf6-dafb48ad0b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights.h5\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c9d14ef9-9e27-4f92-b7bb-3b3baee086a9\", \"my_model_weights.h5\", 2406664)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPiJ_b1S4T-I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}